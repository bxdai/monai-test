{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import tempfile\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import monai\n",
    "from monai.data import create_test_image_2d, list_data_collate, decollate_batch\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    AddChanneld,\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    LoadImaged,\n",
    "    RandCropByPosNegLabeld,\n",
    "    RandRotate90d,\n",
    "    ScaleIntensityd,\n",
    "    EnsureTyped,\n",
    "    EnsureType,\n",
    "    Resized,\n",
    "    SqueezeDimd,\n",
    "    RandFlipd,\n",
    "    NormalizeIntensityd,\n",
    "    CropForegroundd,\n",
    "    ScaleIntensityRanged,\n",
    "    RandAffined,\n",
    ")\n",
    "from monai.visualize import plot_2d_or_3d_image\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "monai.config.print_config()\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MONAI version: 0.7.dev2133\n",
      "Numpy version: 1.21.1\n",
      "Pytorch version: 1.9.0+cu111\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False\n",
      "MONAI rev id: 20ffa3f987fad60a8428ec635fb0b4f6ccca9747\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.4.6\n",
      "Nibabel version: 3.2.1\n",
      "scikit-image version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "Pillow version: 8.3.1\n",
      "Tensorboard version: 2.6.0\n",
      "gdown version: 3.13.0\n",
      "TorchVision version: 0.10.0+cu111\n",
      "tqdm version: 4.62.0\n",
      "lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "psutil version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "pandas version: 1.3.2\n",
      "einops version: 0.3.0\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    " # define transforms for image and segmentation\n",
    "    train_transforms = Compose(\n",
    "        [\n",
    "            LoadImaged(keys=[\"img\", \"seg\"]),\n",
    "            SqueezeDimd(keys=['img', 'seg'], dim=-1),\n",
    "            AddChanneld(keys=[\"img\", \"seg\"]),\n",
    "            ScaleIntensityd(keys=[\"img\", \"seg\"]),\n",
    "        #     ScaleIntensityRanged(\n",
    "        #     keys=[\"image\"], a_min=-57, a_max=164,\n",
    "        #     b_min=0.0, b_max=1.0, clip=True,\n",
    "        # ),\n",
    "            CropForegroundd(keys=[\"img\", \"seg\"], source_key=\"img\"),\n",
    "            RandCropByPosNegLabeld(\n",
    "                keys=[\"img\", \"seg\"],\n",
    "                label_key=\"seg\",\n",
    "                spatial_size=[192, 192],\n",
    "                pos=1,\n",
    "                neg=1,\n",
    "                num_samples=8,\n",
    "            ),\n",
    "            RandRotate90d(keys=[\"img\", \"seg\"], prob=0.10, spatial_axes=[0, 1]),\n",
    "            RandFlipd(\n",
    "                keys=[\"img\", \"seg\"],\n",
    "                spatial_axis=[0],\n",
    "                prob=0.10,\n",
    "            ),\n",
    "            RandFlipd(\n",
    "                keys=[\"img\", \"img\"],\n",
    "                spatial_axis=[1],\n",
    "                prob=0.10,\n",
    "            ),\n",
    "            #NormalizeIntensityd(keys=\"img\", nonzero=True, channel_wise=True),\n",
    "              # user can also add other random transforms\n",
    "            # RandAffined(\n",
    "            #     keys=['img', 'seg'],\n",
    "            #     mode=('bilinear', 'nearest'),\n",
    "            #     prob=1.0, spatial_size=(192, 192),\n",
    "            #     rotate_range=(0, 0, np.pi/15),\n",
    "            #     scale_range=(0.1, 0.1, 0.1)),\n",
    "            EnsureTyped(keys=[\"img\", \"seg\"]),\n",
    "        ]\n",
    "    )\n",
    "    val_transforms = Compose(\n",
    "        [\n",
    "            LoadImaged(keys=[\"img\", \"seg\"]),\n",
    "            SqueezeDimd(keys=['img', 'seg'], dim=-1),\n",
    "            AddChanneld(keys=[\"img\", \"seg\"]),\n",
    "            ScaleIntensityd(keys=[\"img\", \"seg\"]),\n",
    "            CropForegroundd(keys=[\"img\", \"seg\"], source_key=\"img\"),\n",
    "            #NormalizeIntensityd(keys=\"img\", nonzero=True, channel_wise=True),\n",
    "            EnsureTyped(keys=[\"img\", \"seg\"]),\n",
    "        ]\n",
    "    )\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def main(traindir,valdir):\n",
    "    '''main function\n",
    "       start \n",
    "    '''\n",
    "    # images = sorted(glob(os.path.join(data_dir, \"img*.nii.gz\")))\n",
    "    # segs = sorted(glob(os.path.join(data_dir, \"label*.nii.gz\")))\n",
    "    # #print(images)\n",
    "    # print(f\"image size:{len(images)}\")\n",
    "    # #print(segs)\n",
    "    # print(f\"label size:{len(segs)}\")\n",
    "    # train_files = [{\"img\": img, \"seg\": seg} for img, seg in zip(images[:32], segs[:32])]\n",
    "    # val_files = [{\"img\": img, \"seg\": seg} for img, seg in zip(images[-12:], segs[-12:])]\n",
    "\n",
    "    images_train = sorted(glob(os.path.join(traindir, \"img*.nii.gz\")))\n",
    "    segs_train = sorted(glob(os.path.join(traindir, \"label*.nii.gz\")))\n",
    "    #print(images)\n",
    "    print(f\"image size:{len(images_train)}\")\n",
    "    #print(segs)\n",
    "    print(f\"label size:{len(segs_train)}\")\n",
    "    train_files = [{\"img\": img, \"seg\": seg} for img, seg in zip(images_train, segs_train)]\n",
    "\n",
    "\n",
    "    images_val = sorted(glob(os.path.join(valdir, \"img*.nii.gz\")))\n",
    "    segs_val = sorted(glob(os.path.join(valdir, \"label*.nii.gz\")))\n",
    "    #print(images)\n",
    "    print(f\"image size:{len(images_val)}\")\n",
    "    #print(segs)\n",
    "    print(f\"label size:{len(segs_val)}\")\n",
    "    val_files = [{\"img\": img, \"seg\": seg} for img, seg in zip(images_val, segs_val)]\n",
    "\n",
    "    # define transforms for image and segmentation\n",
    "    train_transforms = Compose(\n",
    "        [\n",
    "            LoadImaged(keys=[\"img\", \"seg\"]),\n",
    "            SqueezeDimd(keys=['img', 'seg'], dim=-1),\n",
    "            AddChanneld(keys=[\"img\", \"seg\"]),\n",
    "            ScaleIntensityd(keys=[\"img\", \"seg\"]),\n",
    "        #     ScaleIntensityRanged(\n",
    "        #     keys=[\"image\"], a_min=-57, a_max=164,\n",
    "        #     b_min=0.0, b_max=1.0, clip=True,\n",
    "        # ),\n",
    "            CropForegroundd(keys=[\"img\", \"seg\"], source_key=\"img\"),\n",
    "            RandCropByPosNegLabeld(\n",
    "                keys=[\"img\", \"seg\"],\n",
    "                label_key=\"seg\",\n",
    "                spatial_size=[192, 192],\n",
    "                pos=1,\n",
    "                neg=1,\n",
    "                num_samples=8,\n",
    "            ),\n",
    "            RandRotate90d(keys=[\"img\", \"seg\"], prob=0.10, spatial_axes=[0, 1]),\n",
    "            RandFlipd(\n",
    "                keys=[\"img\", \"seg\"],\n",
    "                spatial_axis=[0],\n",
    "                prob=0.10,\n",
    "            ),\n",
    "            RandFlipd(\n",
    "                keys=[\"img\", \"seg\"],\n",
    "                spatial_axis=[1],\n",
    "                prob=0.10,\n",
    "            ),\n",
    "            #NormalizeIntensityd(keys=\"img\", nonzero=True, channel_wise=True),\n",
    "              # user can also add other random transforms\n",
    "            # RandAffined(\n",
    "            #     keys=['img', 'seg'],\n",
    "            #     mode=('bilinear', 'nearest'),\n",
    "            #     prob=1.0, spatial_size=(192, 192),\n",
    "            #     rotate_range=(0, 0, np.pi/15),\n",
    "            #     scale_range=(0.1, 0.1, 0.1)),\n",
    "            EnsureTyped(keys=[\"img\", \"seg\"]),\n",
    "        ]\n",
    "    )\n",
    "    val_transforms = Compose(\n",
    "        [\n",
    "            LoadImaged(keys=[\"img\", \"seg\"]),\n",
    "            SqueezeDimd(keys=['img', 'seg'], dim=-1),\n",
    "            AddChanneld(keys=[\"img\", \"seg\"]),\n",
    "            ScaleIntensityd(keys=[\"img\", \"seg\"]),\n",
    "            CropForegroundd(keys=[\"img\", \"seg\"], source_key=\"img\"),\n",
    "            #NormalizeIntensityd(keys=\"img\", nonzero=True, channel_wise=True),\n",
    "            EnsureTyped(keys=[\"img\", \"seg\"]),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # define dataset, data loader\n",
    "    check_ds = monai.data.Dataset(data=train_files, transform=train_transforms)\n",
    "    # use batch_size=2 to load images and use RandCropByPosNegLabeld to generate 2 x 4 images for network training\n",
    "    check_loader = DataLoader(check_ds, batch_size=2,\n",
    "                          num_workers=4, collate_fn=list_data_collate)\n",
    "    check_data = monai.utils.misc.first(check_loader)\n",
    "    print(check_data[\"img\"].shape, check_data[\"seg\"].shape)\n",
    "    \n",
    "    # create a training data loader\n",
    "    train_ds = monai.data.Dataset(data=train_files, transform=train_transforms)\n",
    "    # use batch_size=2 to load images and use RandCropByPosNegLabeld to generate 2 x 4 images for network training\n",
    "    train_loader = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=2,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        collate_fn=list_data_collate,\n",
    "        pin_memory=torch.cuda.is_available(),\n",
    "    )\n",
    "\n",
    "    # create a validation data loader\n",
    "    val_ds = monai.data.Dataset(data=val_files, transform=val_transforms)\n",
    "    val_loader = DataLoader(val_ds, batch_size=1,\n",
    "                            num_workers=4, collate_fn=list_data_collate)\n",
    "    dice_metric = DiceMetric(include_background=True,\n",
    "                            reduction=\"mean\", get_not_nans=False)\n",
    "    post_trans = Compose([EnsureType(), Activations(\n",
    "        sigmoid=True), AsDiscrete(threshold_values=True)])\n",
    "    # create UNet, DiceLoss and Adam optimizer\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = monai.networks.nets.UNet(\n",
    "        dimensions=2,\n",
    "        in_channels=1,\n",
    "        out_channels=1,\n",
    "        channels=(16, 32, 64, 128, 256),\n",
    "        strides=(2, 2, 2, 2),\n",
    "        num_res_units=2,\n",
    "    ).to(device)\n",
    "    loss_function = monai.losses.DiceLoss(sigmoid=True)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), 1e-3)\n",
    "# start a typical PyTorch training\n",
    "    max_iterations = 5000  \n",
    "    val_interval = 2\n",
    "    best_metric = -1\n",
    "    best_metric_epoch = -1\n",
    "    epoch_loss_values = list()\n",
    "    metric_values = list()\n",
    "    writer = SummaryWriter()\n",
    "    for epoch in range(max_iterations):\n",
    "        print(\"-\" * 10)\n",
    "        print(f\"epoch {epoch + 1}/{max_iterations}\")\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        step = 0\n",
    "        for batch_data in train_loader:\n",
    "            step += 1\n",
    "            inputs, labels = batch_data[\"img\"].to(device), batch_data[\"seg\"].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_len = len(train_ds) // train_loader.batch_size\n",
    "            #print(f\"{step}/{epoch_len}, train_loss: {loss.item():.4f}\")\n",
    "            writer.add_scalar(\"train_loss\", loss.item(), epoch_len * epoch + step)\n",
    "        epoch_loss /= step\n",
    "        epoch_loss_values.append(epoch_loss)\n",
    "        print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "\n",
    "        if (epoch + 1) % val_interval == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_images = None\n",
    "                val_labels = None\n",
    "                val_outputs = None\n",
    "                for val_data in val_loader:\n",
    "                    val_images, val_labels = val_data[\"img\"].to(device), val_data[\"seg\"].to(device)\n",
    "                    roi_size = (192, 192)\n",
    "                    sw_batch_size = 4\n",
    "                    val_outputs = sliding_window_inference(val_images, roi_size, sw_batch_size, model)\n",
    "                    val_outputs = [post_trans(i) for i in decollate_batch(val_outputs)]\n",
    "                    # compute metric for current iteration\n",
    "                    dice_metric(y_pred=val_outputs, y=val_labels)\n",
    "                # aggregate the final mean dice result\n",
    "                metric = dice_metric.aggregate().item()\n",
    "                # reset the status for next validation round\n",
    "                dice_metric.reset()\n",
    "                metric_values.append(metric)\n",
    "                if metric > best_metric:\n",
    "                    best_metric = metric\n",
    "                    best_metric_epoch = epoch + 1\n",
    "                    torch.save(model.state_dict(), \"best4_metric_model_segmentation2d_dict.pth\")\n",
    "                    print(\"saved new best metric model\")\n",
    "                # print(\n",
    "                #     \"current epoch: {} current mean dice: {:.4f} best mean dice: {:.4f} at epoch {}\".format(\n",
    "                #         epoch + 1, metric, best_metric, best_metric_epoch\n",
    "                #     )\n",
    "                #)\n",
    "                writer.add_scalar(\"val_mean_dice\", metric, epoch + 1)\n",
    "                # plot the last model output as GIF image in TensorBoard with the corresponding image and label\n",
    "                plot_2d_or_3d_image(val_images, epoch + 1, writer, index=0, tag=\"image\")\n",
    "                plot_2d_or_3d_image(val_labels, epoch + 1, writer, index=0, tag=\"label\")\n",
    "                plot_2d_or_3d_image(val_outputs, epoch + 1, writer, index=0, tag=\"output\")\n",
    "\n",
    "    print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")\n",
    "    writer.close()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "if __name__ == \"__main__\":\n",
    "    root_dir = os.getcwd()\n",
    "    train_dir = os.path.join(root_dir, \"data/imagesTr\")\n",
    "    val_dir = os.path.join(root_dir, \"data/imagesTs\")\n",
    "    #print(train_dir)\n",
    "    #print(val_dir)\n",
    "    main(train_dir,val_dir)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/home/xindong/project/monai-test/unet-segment2d/data/imagesTr\n",
      "/home/xindong/project/monai-test/unet-segment2d/data/imagesTs\n",
      "image size:40\n",
      "label size:40\n",
      "image size:17\n",
      "label size:17\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('monaienv': venv)"
  },
  "interpreter": {
   "hash": "41cc7d8094642f0aa3e27d256eb25d3485d313a694ac935cfb444781e1af4b99"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}