{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import tempfile\n",
    "from glob import glob\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import monai\n",
    "from monai.data import create_test_image_2d, list_data_collate, decollate_batch\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.networks.nets import UNet\n",
    "from monai.transforms import Activations, AddChanneld, AsDiscrete, Compose, LoadImaged, SaveImage, ScaleIntensityd, EnsureTyped, EnsureType,SqueezeDimd,CropForegroundd\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def showImage(img_data,lab_data,output_data,i):\n",
    "      print(img_data.size())\n",
    "      img_data = img_data.cpu().squeeze()\n",
    "      lab_data = lab_data.cpu().squeeze()\n",
    "      output_data = output_data.cpu().squeeze()\n",
    "      # img = img_data.numpy()\n",
    "      # lab = lab_data.numpy()\n",
    "      print(img_data.size())\n",
    "      print(f\"image type:{type(img_data)}\\n labe_type:{type(lab_data)}\")\n",
    "      # plot the slice [:, :, 80]\n",
    "      plt.figure(\"check\")\n",
    "      plt.subplot(1, 3, 1)\n",
    "      plt.title(f\"image {i}\")\n",
    "      plt.imshow(img_data, cmap=\"gray\")\n",
    "      plt.subplot(1, 3, 2)\n",
    "      plt.title(f\"label {i}\")\n",
    "      plt.imshow(lab_data)\n",
    "      plt.subplot(1, 3, 3)\n",
    "      plt.title(f\"output {i}\")\n",
    "      plt.imshow(output_data)\n",
    "      plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "def main(tempdir):\n",
    "    monai.config.print_config()\n",
    "    logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "\n",
    "    images = sorted(glob(os.path.join(tempdir, \"img*.nii.gz\")))\n",
    "    segs = sorted(glob(os.path.join(tempdir, \"label*.nii.gz\")))\n",
    "    #print(images)\n",
    "    print(f\"image size:{len(images)}\")\n",
    "    #print(segs)\n",
    "    print(f\"label size:{len(segs)}\")\n",
    "\n",
    "    val_files = [{\"img\": img, \"seg\": seg} for img, seg in zip(images, segs)]\n",
    "\n",
    "    # define transforms for image and segmentation\n",
    "    val_transforms = Compose(\n",
    "        [\n",
    "            # LoadImaged(keys=[\"img\", \"seg\"]),\n",
    "            # AddChanneld(keys=[\"img\", \"seg\"]),\n",
    "            # ScaleIntensityd(keys=\"img\"),\n",
    "            # EnsureTyped(keys=[\"img\", \"seg\"]),\n",
    "            \n",
    "            LoadImaged(keys=[\"img\", \"seg\"]),\n",
    "            SqueezeDimd(keys=['img', 'seg'], dim=-1),\n",
    "            AddChanneld(keys=[\"img\", \"seg\"]),\n",
    "            ScaleIntensityd(keys=[\"img\", \"seg\"]),\n",
    "            CropForegroundd(keys=[\"img\", \"seg\"], source_key=\"img\"),\n",
    "            #NormalizeIntensityd(keys=\"img\", nonzero=True, channel_wise=True),\n",
    "            EnsureTyped(keys=[\"img\", \"seg\"]),\n",
    "        ]\n",
    "    )\n",
    "    val_ds = monai.data.Dataset(data=val_files, transform=val_transforms)\n",
    "    # sliding window inference need to input 1 image in every iteration\n",
    "    val_loader = DataLoader(val_ds, batch_size=1, num_workers=4, collate_fn=list_data_collate)\n",
    "    dice_metric = DiceMetric(include_background=True, reduction=\"mean\", get_not_nans=False)\n",
    "    post_trans = Compose([EnsureType(), Activations(sigmoid=True), AsDiscrete(threshold_values=True)])\n",
    "    saver = SaveImage(output_dir=\"./output\", output_ext=\".nii.gz\", output_postfix=\"seg\")\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = UNet(\n",
    "        dimensions=2,\n",
    "        in_channels=1,\n",
    "        out_channels=1,\n",
    "        channels=(16, 32, 64, 128, 256),\n",
    "        strides=(2, 2, 2, 2),\n",
    "        num_res_units=2,\n",
    "    ).to(device)\n",
    "\n",
    "    model.load_state_dict(torch.load(\"best3_metric_model_segmentation2d_dict.pth\"))\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for val_data in val_loader:\n",
    "            val_images, val_labels = val_data[\"img\"].to(device), val_data[\"seg\"].to(device)\n",
    "            # define sliding window size and batch size for windows inference\n",
    "            roi_size = (192, 192)\n",
    "            sw_batch_size = 4\n",
    "            val_outputs = sliding_window_inference(val_images, roi_size, sw_batch_size, model)\n",
    "            val_outputs = [post_trans(i) for i in decollate_batch(val_outputs)]\n",
    "            val_labels = decollate_batch(val_labels)\n",
    "            # compute metric for current iteration\n",
    "            dice_metric(y_pred=val_outputs, y=val_labels)\n",
    "            step = 0\n",
    "            for val_output in val_outputs:\n",
    "                step = step + 1\n",
    "                saver(val_output)\n",
    "                showImage(val_images,val_labels,val_output,step)\n",
    "        # aggregate the final mean dice result\n",
    "        print(\"evaluation metric:\", dice_metric.aggregate().item())\n",
    "        # reset the status\n",
    "        dice_metric.reset()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root_dir = os.getcwd()\n",
    "    data_dir = os.path.join(root_dir, \"data/imagesTs\")\n",
    "    print(data_dir)\n",
    "    main(data_dir)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/home/xindong/project/monai-test/unet-segment2d/data/imagesTs\n",
      "MONAI version: 0.7.dev2133\n",
      "Numpy version: 1.21.1\n",
      "Pytorch version: 1.9.0+cu111\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False\n",
      "MONAI rev id: 20ffa3f987fad60a8428ec635fb0b4f6ccca9747\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.4.6\n",
      "Nibabel version: 3.2.1\n",
      "scikit-image version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "Pillow version: 8.3.1\n",
      "Tensorboard version: 2.6.0\n",
      "gdown version: 3.13.0\n",
      "TorchVision version: 0.10.0+cu111\n",
      "tqdm version: 4.62.0\n",
      "lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "psutil version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "pandas version: 1.3.2\n",
      "einops version: 0.3.0\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n",
      "image size:5\n",
      "label size:5\n",
      "file written: /home/xindong/project/monai-test/unet-segment2d/output/0/0_seg.nii.gz.\n",
      "torch.Size([1, 1, 1024, 1024])\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'cpu'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_133118/1673820459.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"data/imagesTs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_133118/1673820459.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(tempdir)\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0msaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                 \u001b[0mshowImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;31m# aggregate the final mean dice result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"evaluation metric:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdice_metric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_133118/385309562.py\u001b[0m in \u001b[0;36mshowImage\u001b[0;34m(img_data, lab_data, output_data, i)\u001b[0m\n\u001b[1;32m      4\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0mimg_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m       \u001b[0mlab_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlab_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m       \u001b[0moutput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m       \u001b[0;31m# img = img_data.numpy()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'cpu'"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('monaienv': venv)"
  },
  "interpreter": {
   "hash": "41cc7d8094642f0aa3e27d256eb25d3485d313a694ac935cfb444781e1af4b99"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}